{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68T-QoWtUa2J"
   },
   "source": [
    "install packagees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "88tI9G7nUc1P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler, MultiLabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    precision_recall_curve,\n",
    ")\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiZLto2QUdJx"
   },
   "source": [
    "prepare/process data\n",
    " - normalize numerical col\n",
    " - create one hot encoding\n",
    " - create feature matric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vW735wGUijH",
    "outputId": "1f71516f-974f-4fd1-f25e-46014a0c2caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tconst titleType                                       primaryTitle  \\\n",
      "14035  tt0035423     movie                                     Kate & Leopold   \n",
      "33106  tt0062336     movie  The Tango of the Widower and Its Distorting Mi...   \n",
      "36801  tt0067758     movie                            Simón, contamos contigo   \n",
      "37664  tt0069049     movie                         The Other Side of the Wind   \n",
      "38671  tt0070596     movie                                  Socialist Realism   \n",
      "\n",
      "       isAdult  startYear                            genres  \\\n",
      "14035        0       2001  ['Comedy', 'Fantasy', 'Romance']   \n",
      "33106        0       2020                         ['Drama']   \n",
      "36801        0       2015               ['Comedy', 'Drama']   \n",
      "37664        0       2018                         ['Drama']   \n",
      "38671        0       2023                         ['Drama']   \n",
      "\n",
      "                             directorNames  \\\n",
      "14035                    ['James Mangold']   \n",
      "33106  ['Raúl Ruiz', ' Valeria Sarmiento']   \n",
      "36801                  ['Ramón Fernández']   \n",
      "37664                     ['Orson Welles']   \n",
      "38671  ['Raúl Ruiz', ' Valeria Sarmiento']   \n",
      "\n",
      "                                             writerNames  averageRating  \\\n",
      "14035                ['Steven Rogers', ' James Mangold']            6.4   \n",
      "33106             ['Raúl Ruiz', ' Omar Saavedra Santis']            6.5   \n",
      "36801   ['Juan José Alonso Millán', ' Rafael J. Salvia']            4.2   \n",
      "37664                     ['Orson Welles', ' Oja Kodar']            6.7   \n",
      "38671  ['Cesare Pavese', ' Raúl Ruiz', ' Valeria Sarm...            7.4   \n",
      "\n",
      "       numVotes  \n",
      "14035     90431  \n",
      "33106       194  \n",
      "36801        47  \n",
      "37664      8177  \n",
      "38671        73  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/4sm5vl2d7_xdd0jwk0tgnhn00000gn/T/ipykernel_12161/1304589896.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna('Unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"cleaned_data.csv\")\n",
    "user_data = pd.read_csv(\"user_data.csv\")\n",
    "#print(data.head())\n",
    "\n",
    "# Convert 'startYear' to numeric if it's not already\n",
    "data['startYear'] = pd.to_numeric(data['startYear'], errors='coerce')\n",
    "\n",
    "# Handle missing values in numerical columns by filling with the mean or median\n",
    "numerical_cols = ['startYear', 'averageRating', 'numVotes']\n",
    "for col in numerical_cols:\n",
    "    if data[col].isnull().sum() > 0:\n",
    "        data[col].fillna(data[col].median(), inplace=True)\n",
    "        #print(f\"Filled missing values in {col} with median.\")\n",
    "\n",
    "# For categorical columns, fill missing values with a placeholder or mode\n",
    "categorical_cols = ['titleType', 'genres', 'directorNames', 'writerNames', 'isAdult']\n",
    "for col in categorical_cols:\n",
    "    data[col].fillna('Unknown', inplace=True)\n",
    "    #print(f\"Filled missing values in {col} with 'Unknown'.\")\n",
    "\n",
    "data = data[data['startYear'] > 2000]\n",
    "print(data.head())\n",
    "#print(user_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "WRFWanUijU9k",
    "outputId": "a42b0ad2-b4dd-4f88-f5bc-93e861b4f4d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns normalized successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>genres</th>\n",
       "      <th>directorNames</th>\n",
       "      <th>writerNames</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>titleType_movie</th>\n",
       "      <th>isAdult_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Talk-Show</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14035</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>71618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Comedy', 'Fantasy', 'Romance']</td>\n",
       "      <td>41219</td>\n",
       "      <td>110297</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.030765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33106</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>146903</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>79534</td>\n",
       "      <td>96010</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36801</th>\n",
       "      <td>tt0067758</td>\n",
       "      <td>120996</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>78880</td>\n",
       "      <td>59871</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37664</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>142964</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>72832</td>\n",
       "      <td>88176</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38671</th>\n",
       "      <td>tt0070596</td>\n",
       "      <td>122641</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>79534</td>\n",
       "      <td>19735</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst  primaryTitle  startYear                            genres  \\\n",
       "14035  tt0035423         71618   0.000000  ['Comedy', 'Fantasy', 'Romance']   \n",
       "33106  tt0062336        146903   0.826087                         ['Drama']   \n",
       "36801  tt0067758        120996   0.608696               ['Comedy', 'Drama']   \n",
       "37664  tt0069049        142964   0.739130                         ['Drama']   \n",
       "38671  tt0070596        122641   0.956522                         ['Drama']   \n",
       "\n",
       "       directorNames  writerNames  averageRating  numVotes  titleType_movie  \\\n",
       "14035          41219       110297       0.600000  0.030765              1.0   \n",
       "33106          79534        96010       0.611111  0.000064              1.0   \n",
       "36801          78880        59871       0.355556  0.000014              1.0   \n",
       "37664          72832        88176       0.633333  0.002780              1.0   \n",
       "38671          79534        19735       0.711111  0.000023              1.0   \n",
       "\n",
       "       isAdult_0  ...  Mystery News  Reality-TV  Romance  Sci-Fi  Sport  \\\n",
       "14035        1.0  ...      0.0  0.0         0.0      0.0     0.0    0.0   \n",
       "33106        1.0  ...      0.0  0.0         0.0      0.0     0.0    0.0   \n",
       "36801        1.0  ...      0.0  0.0         0.0      0.0     0.0    0.0   \n",
       "37664        1.0  ...      0.0  0.0         0.0      1.0     0.0    0.0   \n",
       "38671        1.0  ...      0.0  0.0         0.0      0.0     0.0    0.0   \n",
       "\n",
       "       Talk-Show  Thriller  War  Western  \n",
       "14035        0.0       0.0  0.0      0.0  \n",
       "33106        0.0       0.0  0.0      0.0  \n",
       "36801        0.0       0.0  0.0      0.0  \n",
       "37664        0.0       0.0  0.0      0.0  \n",
       "38671        0.0       0.0  1.0      0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# movie data\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = ['startYear', 'averageRating', 'numVotes']\n",
    "\n",
    "# Fit and transform the data\n",
    "data = data.copy()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
    "\n",
    "print(\"Numerical columns normalized successfully!\")\n",
    "data[numerical_cols].head()\n",
    "\n",
    "# One-Hot Encode 'titleType' and 'isAdult'\n",
    "data = pd.get_dummies(data, columns=['titleType', 'isAdult'], prefix=['titleType', 'isAdult'])\n",
    "\n",
    "# 0 and 1 assignment for titleType_movie, isAdult_0, isAdult_1\n",
    "data[[\"titleType_movie\", \"isAdult_0\", \"isAdult_1\"]] = data[[\"titleType_movie\", \"isAdult_0\", \"isAdult_1\"]].astype(int)\n",
    "\n",
    "# genre multi-encoding\n",
    "data['genre_list'] = data['genres'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "# mlb encoder\n",
    "multi_label_encoder = MultiLabelBinarizer()\n",
    "genres_encoded = multi_label_encoder.fit_transform(data['genre_list'])\n",
    "genres_encoded_df = pd.DataFrame(genres_encoded, columns=multi_label_encoder.classes_)\n",
    "data = pd.concat([data, genres_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "#print(user_data.head())\n",
    "\n",
    "# director label encoding\n",
    "movie_encoder = LabelEncoder()\n",
    "\n",
    "data['directorNames'] = movie_encoder.fit_transform(data['directorNames'])\n",
    "\n",
    "# writer label encoding\n",
    "data['writerNames'] = movie_encoder.fit_transform(data['writerNames'])\n",
    "\n",
    "# movie_id using label encoding\n",
    "data[\"primaryTitle\"] = movie_encoder.fit_transform(data[\"primaryTitle\"])\n",
    "\n",
    "\n",
    "data.head()\n",
    "#print(data.columns)\n",
    "#user_data.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "iTB3HVz3JOqX",
    "outputId": "36383bce-185a-4928-a497-3756ea6feffb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>UserRating</th>\n",
       "      <th>FavoriteGenres</th>\n",
       "      <th>FavoriteActors</th>\n",
       "      <th>FavoriteDirectors</th>\n",
       "      <th>user_genre_list</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adult</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Talk-Show</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000009</td>\n",
       "      <td>149138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>['Romance']</td>\n",
       "      <td>149</td>\n",
       "      <td>19868</td>\n",
       "      <td>[Romance]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111111</td>\n",
       "      <td>tt0000147</td>\n",
       "      <td>224595</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>['News', 'Documentary', 'Sport']</td>\n",
       "      <td>49</td>\n",
       "      <td>46569</td>\n",
       "      <td>[News, Documentary, Sport]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222222</td>\n",
       "      <td>tt0000502</td>\n",
       "      <td>35350</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>[]</td>\n",
       "      <td>299</td>\n",
       "      <td>105924</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>252417</td>\n",
       "      <td>tt0000574</td>\n",
       "      <td>247271</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>['Action']</td>\n",
       "      <td>249</td>\n",
       "      <td>33864</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>263528</td>\n",
       "      <td>tt0000591</td>\n",
       "      <td>242575</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>144</td>\n",
       "      <td>89998</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID     tconst  primaryTitle  UserRating  \\\n",
       "0       0  tt0000009        149138    0.000000   \n",
       "1  111111  tt0000147        224595    0.444444   \n",
       "2  222222  tt0000502         35350    0.888889   \n",
       "3  252417  tt0000574        247271    0.777778   \n",
       "4  263528  tt0000591        242575    0.888889   \n",
       "\n",
       "                     FavoriteGenres  FavoriteActors  FavoriteDirectors  \\\n",
       "0                       ['Romance']             149              19868   \n",
       "1  ['News', 'Documentary', 'Sport']              49              46569   \n",
       "2                                []             299             105924   \n",
       "3                        ['Action']             249              33864   \n",
       "4                         ['Drama']             144              89998   \n",
       "\n",
       "              user_genre_list  Action  Adult  ...  Mystery  News  Reality-TV  \\\n",
       "0                   [Romance]       0      0  ...        0     0           0   \n",
       "1  [News, Documentary, Sport]       0      0  ...        0     1           0   \n",
       "2                          []       0      0  ...        0     0           0   \n",
       "3                    [Action]       1      0  ...        0     0           0   \n",
       "4                     [Drama]       0      0  ...        0     0           0   \n",
       "\n",
       "   Romance  Sci-Fi  Sport  Talk-Show  Thriller  War  Western  \n",
       "0        1       0      0          0         0    0        0  \n",
       "1        0       0      1          0         0    0        0  \n",
       "2        0       0      0          0         0    0        0  \n",
       "3        0       0      0          0         0    0        0  \n",
       "4        0       0      0          0         0    0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_data\n",
    "\n",
    "user_numerical_cols = ['UserRating']\n",
    "\n",
    "user_data[user_numerical_cols] = scaler.fit_transform(user_data[user_numerical_cols])\n",
    "\n",
    "user_data['user_genre_list'] = user_data['FavoriteGenres'].apply(lambda x: eval(x) if isinstance(x, str) else x)\n",
    "user_genres_encoded = multi_label_encoder.fit_transform(user_data['user_genre_list'])\n",
    "user_genres_encoded_df = pd.DataFrame(user_genres_encoded, columns=multi_label_encoder.classes_)\n",
    "user_data = pd.concat([user_data, user_genres_encoded_df], axis=1)\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "\n",
    "# director label encoding\n",
    "user_data['FavoriteDirectors'] = user_encoder.fit_transform(user_data['FavoriteDirectors'])\n",
    "\n",
    "# writer label encoding\n",
    "user_data['FavoriteActors'] = user_encoder.fit_transform(user_data['FavoriteActors'])\n",
    "\n",
    "# movie_id label encoding\n",
    "user_data[\"primaryTitle\"] = user_encoder.fit_transform(user_data[\"primaryTitle\"])\n",
    "\n",
    "# user_id label ecoding\n",
    "user_data[\"UserID\"] = user_encoder.fit_transform(user_data[\"UserID\"])\n",
    "\n",
    "\n",
    "user_data.head()\n",
    "#print(user_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JkFgg4NDjtdk",
    "outputId": "75b7cc6a-4174-46a0-f8ec-c960928bb144"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>UserID</th>\n",
       "      <th>UserRating</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>genres_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0035423</td>\n",
       "      <td>44847</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.030765</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0062336</td>\n",
       "      <td>244761</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0067758</td>\n",
       "      <td>248866</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0069049</td>\n",
       "      <td>249824</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0070596</td>\n",
       "      <td>250943</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst  UserID  UserRating  averageRating  numVotes  \\\n",
       "0  tt0035423   44847    0.444444       0.600000  0.030765   \n",
       "1  tt0062336  244761    0.777778       0.611111  0.000064   \n",
       "2  tt0067758  248866    0.222222       0.355556  0.000014   \n",
       "3  tt0069049  249824    0.888889       0.633333  0.002780   \n",
       "4  tt0070596  250943    0.555556       0.711111  0.000023   \n",
       "\n",
       "                                         genres_list  \n",
       "0  [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_list = [col for col in data.columns if col not in ['tconst', 'primaryTitle', 'startYear', 'genres', 'directorNames',\n",
    "       'writerNames', 'averageRating', 'numVotes', 'titleType_movie',\n",
    "       'isAdult_0', 'isAdult_1', 'genre_list']]\n",
    "\n",
    "movie_features = pd.concat([data[['tconst', 'averageRating', 'numVotes']]],axis=1)\n",
    "\n",
    "movie_features['genres_list'] = data[genre_list].apply(\n",
    "    lambda genres: [1 if genres[genre] == 1 else 0 for genre in genre_list], axis=1  # Access genre columns by name\n",
    ")\n",
    "\n",
    "# formats user features in an array\n",
    "user_features = pd.concat([user_data[['tconst', 'UserID', 'UserRating']]],axis=1)\n",
    "\n",
    "# merges user and movie data into an array\n",
    "merged_data = pd.merge(user_features, movie_features, on='tconst', how='inner')\n",
    "\n",
    "#creates a dictionary for tconst to movie\n",
    "tconst_to_title = data.set_index('tconst')['primaryTitle'].to_dict()\n",
    "\n",
    "merged_data.head()\n",
    "#print(tconst_to_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZCpoMzlg-RZ",
    "outputId": "3942cbc8-e888-47bf-ba8c-9857f79ec961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "x_input = []\n",
    "\n",
    "for index, row in merged_data.iterrows():\n",
    "    x_input.append(list(row['genres_list']) + [row['averageRating'], row['numVotes'], row['UserRating']])\n",
    "\n",
    "print(len(x_input[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALfG3dt4Ui9X"
   },
   "source": [
    "create vae model design\n",
    " - encoder\n",
    " - decoder\n",
    " - define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TjQ_W3zRVWFY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__( self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim ):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.fc5 = nn.Linear(hidden_dim4, hidden_dim5)\n",
    "        self.fc_mu = nn.Linear(hidden_dim5, latent_dim)      # Mean of latent distribution\n",
    "        self.fc_log_var = nn.Linear(hidden_dim5, latent_dim) # Log variance of latent distribution\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        log_var = self.fc_log_var(x)\n",
    "        return mu, log_var  # Return mean and log variance\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__( self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim5)\n",
    "        self.fc2 = nn.Linear(hidden_dim5, hidden_dim4)\n",
    "        self.fc3 = nn.Linear(hidden_dim4, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim2)\n",
    "        self.fc5 = nn.Linear(hidden_dim2, hidden_dim1)\n",
    "        self.fc_out = nn.Linear(hidden_dim1, input_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = F.relu(self.fc3(z))\n",
    "        z = F.relu(self.fc4(z))\n",
    "        z = F.relu(self.fc5(z))\n",
    "        # might want to change .softmax to .sigmoid\n",
    "        return F.sigmoid(self.fc_out(z))  # Return class probabilities\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4, hidden_dim5, latent_dim)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)  # Standard deviation\n",
    "        epsilon = torch.randn_like(std)  # Random noise\n",
    "        return mu + epsilon * std  # Reparameterization trick\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x)  # Encode input to latent distribution\n",
    "        z = self.reparameterize(mu, log_var)  # Sample latent variable\n",
    "        x_reconstructed = self.decoder(z)  # Decode back to input space\n",
    "        return x_reconstructed, mu, log_var  # Return reconstructed data, mean, and log variance\n",
    "\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, binary_mask, continuous_mask, beta=1.0):\n",
    "    \"\"\"\n",
    "    Loss function for VAE with mixed binary and continuous data.\n",
    "\n",
    "    recon_x: Reconstructed data (output of the decoder)\n",
    "    x: Original input data\n",
    "    mu: Mean of the latent distribution (output of the encoder)\n",
    "    logvar: Log variance of the latent distribution (output of the encoder)\n",
    "    binary_mask: A mask indicating which features are binary (True/False)\n",
    "    continuous_mask: A mask indicating which features are continuous (True/False)\n",
    "    beta: Scaling factor for the KL divergence term (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # Binary Cross-Entropy for binary features\n",
    "    binary_x = x[:, binary_mask]  # Select binary features\n",
    "    recon_binary_x = recon_x[:, binary_mask]  # Reconstructed binary features\n",
    "    binary_recon_loss = F.binary_cross_entropy(recon_binary_x, binary_x, reduction='sum')\n",
    "\n",
    "    # Mean Squared Error for continuous features\n",
    "    continuous_x = x[:, continuous_mask]  # Select continuous features\n",
    "    recon_continuous_x = recon_x[:, continuous_mask]  # Reconstructed continuous features\n",
    "    continuous_recon_loss = F.mse_loss(recon_continuous_x, continuous_x, reduction='sum')\n",
    "\n",
    "    # Combine the reconstruction losses (you can scale continuous loss if necessary)\n",
    "    total_recon_loss = binary_recon_loss + beta * continuous_recon_loss\n",
    "\n",
    "    # KL Divergence Loss\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Total Loss = Reconstruction Loss + KL Divergence\n",
    "    total_loss = total_recon_loss + kl_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGw1VXzBVWxR"
   },
   "source": [
    "Training VAE\n",
    " - train model\n",
    "  - forward pass\n",
    "  - compute loss\n",
    "  - backpropogation\n",
    "  - run for # of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAnkrZyPVZRN",
    "outputId": "86c11030-0e16-4c3a-9d55-22c993ad8ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3743\n",
      "Epoch 2, Loss: 2.2183\n",
      "Epoch 3, Loss: 2.1809\n",
      "Epoch 4, Loss: 2.1668\n",
      "Epoch 5, Loss: 2.1572\n",
      "Epoch 6, Loss: 2.1528\n",
      "Epoch 7, Loss: 2.1542\n",
      "Epoch 8, Loss: 2.1497\n",
      "Epoch 9, Loss: 2.1464\n",
      "Epoch 10, Loss: 2.1501\n",
      "Epoch 11, Loss: 2.1466\n",
      "Epoch 12, Loss: 2.1461\n",
      "Epoch 13, Loss: 2.1439\n",
      "Epoch 14, Loss: 2.1428\n",
      "Epoch 15, Loss: 2.1434\n",
      "Epoch 16, Loss: 2.1440\n",
      "Epoch 17, Loss: 2.1422\n",
      "Epoch 18, Loss: 2.1409\n",
      "Epoch 19, Loss: 2.1405\n",
      "Epoch 20, Loss: 2.1407\n",
      "Epoch 21, Loss: 2.1380\n",
      "Epoch 22, Loss: 2.1402\n",
      "Epoch 23, Loss: 2.1365\n",
      "Epoch 24, Loss: 2.1369\n",
      "Epoch 25, Loss: 2.1378\n",
      "Epoch 26, Loss: 2.1389\n",
      "Epoch 27, Loss: 2.1383\n",
      "Epoch 28, Loss: 2.1399\n",
      "Epoch 29, Loss: 2.1351\n",
      "Epoch 30, Loss: 2.1377\n",
      "Epoch 31, Loss: 2.1359\n",
      "Epoch 32, Loss: 2.1377\n",
      "Epoch 33, Loss: 2.1342\n",
      "Epoch 34, Loss: 2.1355\n",
      "Epoch 35, Loss: 2.1356\n",
      "Epoch 36, Loss: 2.1359\n",
      "Epoch 37, Loss: 2.1369\n",
      "Epoch 38, Loss: 2.1352\n",
      "Epoch 39, Loss: 2.1367\n",
      "Epoch 40, Loss: 2.1364\n",
      "Epoch 41, Loss: 2.1311\n",
      "Epoch 42, Loss: 2.1337\n",
      "Epoch 43, Loss: 2.1341\n",
      "Epoch 44, Loss: 2.1354\n",
      "Epoch 45, Loss: 2.1355\n",
      "Epoch 46, Loss: 2.1335\n",
      "Epoch 47, Loss: 2.1335\n",
      "Epoch 48, Loss: 2.1304\n",
      "Epoch 49, Loss: 2.1338\n",
      "Epoch 50, Loss: 2.1331\n",
      "VAE training complete!\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "# try adding hidden layers\n",
    "HIDDEN_DIM1 = 512\n",
    "HIDDEN_DIM2 = 256\n",
    "HIDDEN_DIM3 = 128\n",
    "HIDDEN_DIM4 = 64\n",
    "HIDDEN_DIM5 = 32\n",
    "LATENT_DIM = 30\n",
    "BIN_MASK = torch.tensor([True, True, True, True, True, True, True, True, True, True,\n",
    "                        True, True, True, True, True, True, True, True, True, True,\n",
    "                        True, True, True, True, True, True, False, False, False])\n",
    "CONT_MASK = torch.tensor([False, False, False, False, False, False, False, False, False, False,\n",
    "                          False, False, False, False, False, False, False, False, False, False,\n",
    "                          False, False, False, False, False, False, True, True, True])\n",
    "\n",
    "# Prepare data for training\n",
    "merged_data_tensor = torch.tensor(x_input, dtype=torch.float32)\n",
    "\n",
    "# Split data:\n",
    "temp_dataset = TensorDataset(merged_data_tensor)\n",
    "train_size = int(0.8 * len(temp_dataset))\n",
    "val_size = len(temp_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(temp_dataset, [train_size, val_size])\n",
    "\n",
    "# hyperparameter tuning, change around the batch_size\n",
    "# grid search, we can change around batch_size = {8,16,32,64}\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size =64, shuffle=False)\n",
    "\n",
    "# Model setup\n",
    "input_dim = merged_data_tensor.shape[1]\n",
    "vae = VAE(input_dim, HIDDEN_DIM1, HIDDEN_DIM2, HIDDEN_DIM3, HIDDEN_DIM4, HIDDEN_DIM5, LATENT_DIM)\n",
    "\n",
    "# changed learning rate to 1e-3 => 1e-5\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "# temporarily change EPOCHS=1\n",
    "EPOCHS = 50\n",
    "vae.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch[0]  # Unpack the TensorDataset\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        recon_batch, mu, logvar = vae(batch)\n",
    "        loss = loss_function(recon_batch, batch, mu, logvar, BIN_MASK, CONT_MASK)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "print(\"VAE training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KENgfAHHVq0H"
   },
   "source": [
    "Generate Latent Representations\n",
    "- evaluate user preferences\n",
    "- compare with other movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tJ1ItQU5V76J"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_user_embeddings(user_rating, movie_features, vae_model):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_vector = torch.tensor(movie_features + [user_rating], dtype=torch.float32)\n",
    "        _, mu, _ = vae_model(input_vector)\n",
    "    return mu.numpy()\n",
    "\n",
    "def reccomend_movies(user_rating, movie_features, movie_embeddings, data, top_n=5):\n",
    "    user_embedding = get_user_embeddings(user_rating, movie_features, vae)\n",
    "\n",
    "    # added a reshape\n",
    "    user_embedding = user_embedding.reshape(-1, 1)\n",
    "\n",
    "    # code crashes here\n",
    "    # print(\"User embeddings is: \", user_embedding)\n",
    "    similarity_scores = cosine_similarity(user_embedding, movie_embeddings)\n",
    "\n",
    "    top_indices = np.argsort(similarity_scores.flatten())[::-1][:top_n]\n",
    "\n",
    "    recommended_movies = data.iloc[top_indices]\n",
    "\n",
    "    recommended_movies['similarity_score'] = similarity_scores.flatten()[top_indices]\n",
    "\n",
    "    return recommended_movies[['tconst', 'primaryTitle', 'averageRating', 'similarity_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2x5kFG7V9KV"
   },
   "source": [
    "Content-Based Recomendations\n",
    " - Compute Similarities\n",
    " - generate reccomendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "4i3SmsPuWMDM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the movie embeddings:\n",
      "  [[ 0]\n",
      " [ 1]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [10]\n",
      " [11]\n",
      " [12]\n",
      " [13]\n",
      " [14]\n",
      " [15]\n",
      " [16]\n",
      " [17]\n",
      " [18]\n",
      " [19]\n",
      " [20]\n",
      " [21]\n",
      " [22]\n",
      " [23]\n",
      " [24]\n",
      " [25]\n",
      " [26]\n",
      " [27]\n",
      " [28]\n",
      " [29]]\n"
     ]
    }
   ],
   "source": [
    "movie_emeddings = []\n",
    "\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    for index, row in movie_features.iterrows():\n",
    "        movie_input = torch.tensor(row['genres_list'] + [row['averageRating'], row['numVotes'], 0.5], dtype=torch.float32)\n",
    "        # _, mu, _ => mu, logvar\n",
    "        mu, _= vae.encoder(movie_input)\n",
    "        movie_emeddings.append(mu.numpy())\n",
    "\n",
    "# try changing NaN to 0\n",
    "movie_emeddings = pd.DataFrame(movie_emeddings)\n",
    "movie_emeddings = movie_emeddings.fillna(0)\n",
    "\n",
    "user_rating = 4.5\n",
    "movie_example_features = [0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 1,\n",
    " 0,\n",
    " 0,\n",
    " 0.5,\n",
    " 6.057523510812793e-06]\n",
    "movie_emeddings = np.vstack(movie_emeddings)\n",
    "print(\"These are the movie embeddings:\\n \", movie_emeddings)\n",
    "# Error occurs here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqTAieYeWPLf"
   },
   "source": [
    "Testing and Validations\n",
    " - Evaluate Reccomendations\n",
    " - Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "FmOuSScsWfzz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          tconst                        primaryTitle  averageRating  \\\n",
      "77718  tt0159369  Cooper and Hemingway: The True Gen       0.711111   \n",
      "95540  tt0225828                              G.O.D.       0.322222   \n",
      "81038  tt0172156                         Bad Boys II       0.622222   \n",
      "81008  tt0171928                A Samba for Sherlock       0.622222   \n",
      "80868  tt0171436      The Kidnapping of Chris Burden       0.711111   \n",
      "\n",
      "       similarity_score  \n",
      "77718               1.0  \n",
      "95540               1.0  \n",
      "81038               1.0  \n",
      "81008               1.0  \n",
      "80868               1.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1y/4sm5vl2d7_xdd0jwk0tgnhn00000gn/T/ipykernel_12161/2755284885.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  recommended_movies['similarity_score'] = similarity_scores.flatten()[top_indices]\n"
     ]
    }
   ],
   "source": [
    "top_movies = reccomend_movies(user_rating, movie_example_features, movie_emeddings, data, top_n=5)\n",
    "top_movies['primaryTitle'] = movie_encoder.inverse_transform(top_movies['primaryTitle'])\n",
    "print(top_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Compared to Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.1485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Testing and Validations\\n - Evaluate Reccomendations\\n - Fine Tune Model\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss = 0\n",
    "\n",
    "vae.eval()\n",
    "\n",
    "with torch.no_grad():  # Disable gradient tracking since we're only evaluating\n",
    "    for batch in val_loader:\n",
    "        batch = batch[0]  # Unpack the TensorDataset (assuming only one tensor, batch[0] is the data)\n",
    "\n",
    "        # Forward pass\n",
    "        recon_batch, mu, logvar = vae(batch)\n",
    "\n",
    "        # Calculate the loss (use your custom loss function, and include masks if necessary)\n",
    "        loss = loss_function(recon_batch, batch, mu, logvar, BIN_MASK, CONT_MASK)\n",
    "\n",
    "        # Accumulate the total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "# Compute the average loss over the entire validation dataset\n",
    "average_loss = total_loss / len(val_loader.dataset)\n",
    "print(f\"Validation Loss: {average_loss:.4f}\")\n",
    "\n",
    "\"\"\"Testing and Validations\n",
    " - Evaluate Reccomendations\n",
    " - Fine Tune Model\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "vae_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
